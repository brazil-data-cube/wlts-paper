{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compressed-stanley",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/brazil-data-cube/code-gallery/master/img/logo-bdc.png\" align=\"right\" width=\"128\"/>\n",
    "\n",
    "# <span style=\"color:#336699\">Web Land Trajectory Service (WLTS) - Comparing LULC data sets</span>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Fabiana Zioti<sup><a href=\"https://orcid.org/0000-0002-7305-6043\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Karine Reis Ferreira<sup><a href=\"https://orcid.org/0000-0003-2656-5504\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Gilberto R. Queiroz<sup><a href=\"https://orcid.org/0000-0001-7534-0219\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Alana K. Neves, Felipe Menino Carlos<sup><a href=\"https://orcid.org/0000-0002-3334-4315\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Felipe Carvalho de Souza<sup><a href=\"https://orcid.org/0000-0002-5826-1700\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Lorena Santos<sup><a href=\"https://orcid.org/0000-0003-2612-5859\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Rolf Simoes<sup><a href=\"https://orcid.org/0000-0003-0953-4132\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    <br/><br/>\n",
    "    Earth Observation and Geoinformatics Division, National Institute for Space Research (INPE)\n",
    "    <br/>\n",
    "    Avenida dos Astronautas, 1758, Jardim da Granja, São José dos Campos, SP 12227-010, Brazil\n",
    "    <br/><br/>\n",
    "    Contact: <a href=\"mailto:brazildatacube@inpe.br\">brazildatacube@inpe.br</a>\n",
    "    <br/><br/>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>This Jupyter Notebook is a supplement of the following paper:</b>\n",
    "    <div style=\"margin-left: 10px; margin-right: 10px; margin-top:10px\">\n",
    "      <p> Zioti, F.; Ferreira, K.R.; Queiroz, G.R.; Neves, A.K.; Carlos, F.M.; Souza, F.C.; Santos, L.; Simoes, R.E; 2021. A platform for land use and land cover data integration and trajectory analysis. </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-angola",
   "metadata": {},
   "source": [
    "### Table 5: Agreement analysis between TerraClass and Mapbiomas, both for 2014. \n",
    "<hr style=\"border:2px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-humor",
   "metadata": {},
   "source": [
    "Import the required librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wlts import WLTS\n",
    "from lccs import LCCS\n",
    "from loguru import logger\n",
    "from tinydb import TinyDB\n",
    "import numpy\n",
    "import pandas\n",
    "import geopandas\n",
    "import json\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-textbook",
   "metadata": {},
   "source": [
    "## 1. Configurations\n",
    "\n",
    "To run the codes presented in this document, we need to make some settings. The first one is the definition of the addresses of the **W**eb **L**and **T**rajectory **S**ervice (WLTS) and **W**eb **L**and **C**lassification **S**ystem **S**ervice (WLCSS) services.\n",
    "\n",
    "Thus, in this example, we will use these services provided by the [Brazil Data Cube project](http://brazildatacube.org/). The addresses are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Web Land Trajectory Service (WLTS) URL\n",
    "#\n",
    "wlts_service_url = \"https://brazildatacube.dpi.inpe.br/wlts/\"\n",
    "\n",
    "#\n",
    "# Web Land Classification System Service (WLCSS) URL\n",
    "#\n",
    "lccs_service_url = \"https://brazildatacube.dpi.inpe.br/lccs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-rouge",
   "metadata": {},
   "source": [
    "To conduct the case study, we will perform trajectory extraction considering two collections:\n",
    "\n",
    "- `MapBiomas Amazônia v5`;\n",
    "- `TerraClass Amazônia v2`;\n",
    "\n",
    "In the code below, these collections defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'terraclass_amazonia-v2,mapbiomas_amazonia-v5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-survival",
   "metadata": {},
   "source": [
    "Information on LULC for these projects is retrieved for the year 2014. For this, we set the date and start and end of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 2014\n",
    "end_date = 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-young",
   "metadata": {},
   "source": [
    "Thus, in this example, we will use these services provided by the [Brazil Data Cube project](http://brazildatacube.org/). The addresses are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Services\n",
    "service = WLTS(wlts_service_url, access_token='change-me')\n",
    "service_lccs = LCCS(lccs_service_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-syria",
   "metadata": {},
   "source": [
    "Additionally, since we will be using the BDC services, defining an **access token** will also be necessary. This token is mandatory, and once created, gives access to all BDC services and data products.\n",
    "\n",
    "> If you do not have an access token, you can create one through [Brazil Data Cube explorer](https://brazildatacube.dpi.inpe.br/portal/), the BDC data portal. In the portal, **create an account**, and in the **user settings**, **create your token**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-thomas",
   "metadata": {},
   "source": [
    "## 2.  Sample points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-detector",
   "metadata": {},
   "source": [
    "Path with the data file of the area of interest. For the case study, LULC trajectories were collected using a systematically generated grid for the São Felix do Xingu/Pará State region in Brazil. In total, `4472` points were generated. All of them are with a spacing of 1km between each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../data/raw_data/study-area_sao-felix-do-xingu/sao-felix-do-xingu_utm_sqr_pts1km.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-purpose",
   "metadata": {},
   "source": [
    "Reads the shapefile that contains the locations of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geopandas.read_file(file_path)\n",
    "df_parts = numpy.array_split(df, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-fireplace",
   "metadata": {},
   "source": [
    "## 3.  Retrieving LULC Harmonize trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-large",
   "metadata": {},
   "source": [
    "Prepare tinydb to save the returned trajectories and use the logger module to to assist in monitoring operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.add(\"../../data/derived_data/python-scripts/download_points_{time}.log\")\n",
    "\n",
    "db = TinyDB('../../data/derived_data/python-scripts/points_wlts.json', ensure_ascii=False)\n",
    "last_row = db.get(doc_id=len(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-kentucky",
   "metadata": {},
   "source": [
    "To compare different LULC data sets, it is necessary to harmonize their distinct classification systems and LULC classes. In order for the LULC trajectory to be returned in a single classification system, it is necessary to define the parameter **target_system** in the function **tj**. The code below searches for each location of interest the trajectory in the classification system **Simplified-legend-TM-1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, part in enumerate(df_parts):\n",
    "    for idx2, row in part.iterrows():\n",
    "#         \n",
    "#       Check if this location has already been consulted.\n",
    "#       If it is a new location, the next step is performed\n",
    "# \n",
    "        if last_row and idx2 <= last_row['id']:\n",
    "            continue\n",
    "# \n",
    "#       Shows in which step the data query is located\n",
    "# \n",
    "        logger.info(f'Part({idx}) | row({idx2})')\n",
    "\n",
    "#     \n",
    "#       Retrieve the LULC path from the WLTS service    \n",
    "# \n",
    "        _res = service.tj(latitude = row.geometry.y,\n",
    "                          longitude = row.geometry.x,\n",
    "                          collections = collections,\n",
    "                          start_date = start_date,\n",
    "                          end_date = end_date,\n",
    "                          target_system='Simplified-legend-TM-1')\n",
    "# \n",
    "#       Save the result using tinydb\n",
    "# \n",
    "        db.insert({'id': idx2, **_res})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-meaning",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
